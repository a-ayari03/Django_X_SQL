{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341e869-845f-49b9-9943-a972a3aaa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import os\n",
    "import regex as re\n",
    "import datetime \n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import datetime\n",
    "import sys\n",
    "from Kernel_lib import *\n",
    "\n",
    "\"\"\"\n",
    "This routine has been made to ease the importation of csv file into the 6Sigma Database\n",
    "\"\"\"\n",
    "## CONSTANT \n",
    "PARENT_PATH = './raw_file' # Must contain every csv file\n",
    "QUERY_PATH = './query_folder' # Must contain every query\n",
    "ARCHIVE_PATH = './historique' # Folder for archive\n",
    "QUERY_ENGINEERING_PATH = ['/home/alexandre/Downloads/query_folder/Vision_spatial.ipynb', '/home/alexandre/Downloads/query_folder/Olivier_it_Workflow.ipynb']\n",
    " # Notebook with all query to launch in order to get a clean csv file\n",
    "\n",
    "TABLE_NAME = 'olivier_it' # FOR EXPORT DATA ONLY\n",
    "\n",
    "database_name = {\"IT_Equipment\": \"IT_Equipment\",\n",
    "                 \"assets_new\": \"Assets\",\n",
    "                 \"olivier_it\": \"Olivier_it\"\n",
    "                }\n",
    "\n",
    "database_file = {}\n",
    "database_scheme = {}\n",
    "database_filename = {}\n",
    "\n",
    "## Establish Connection with 6Sigma\n",
    "host_name = \"localhost\"\n",
    "user_name = \"alexandre\"\n",
    "user_password = \"Sigma64ever\"\n",
    "connection = create_server_connection(host_name, user_name, user_password)\n",
    "db = 'base6sigma'\n",
    "connection = create_db_connection(host_name, user_name, user_password, db)\n",
    "\n",
    "#check_create_directory(ARCHIVE_PATH)    # Check if directory exist \n",
    "#check_create_directory(PARENT_PATH)    # Check if directory exist \n",
    "\n",
    "## Get csv/scheme file for each table \n",
    "dir_ls = [f for f in os.listdir(PARENT_PATH) if os.path.isfile(os.path.join(PARENT_PATH, f))]  # list all csv file\n",
    "\n",
    "dir_ls_query = os.listdir(QUERY_PATH)   # list all query file\n",
    "\n",
    "for db_name in database_name :\n",
    "\tkey = database_name[db_name]\n",
    "\tdatabase_file[db_name] = None\n",
    "\tfor file in dir_ls : \n",
    "\t\tif key.lower().strip() in file.lower().strip() and \".csv\" in file :\n",
    "\t\t\tif key.lower().strip() == 'olivier_it' and \"noindex\" not in file.lower().strip():\n",
    "\t\t\t\tdatabase_file[db_name] = os.path.join(PARENT_PATH, file)\n",
    "\t\t\t\tdatabase_filename[db_name]=file\n",
    "\t\tfor file in dir_ls_query :\n",
    "\t\t\tif db_name.lower().strip()+\"_sql_query\" in file.lower().strip() : \n",
    "\t\t\t\tdatabase_scheme[db_name] = os.path.join(QUERY_PATH, file)\n",
    "\n",
    "for db_name in database_name :\n",
    "\tif database_file[db_name] != None :\n",
    "\t\t# 1/ get csv\n",
    "\t\tkey = database_name[db_name]\n",
    "\t\tprint(f\"db name : {db_name}\")\n",
    "\t\tfilepath = database_file[db_name]\n",
    "\t\tif db_name not in ['assets_new', 'olivier_it'] :\n",
    "\t\t\tdf = get_csv_to_df(filepath, db_name)\n",
    "\t\telse :\n",
    "\t\t\tdf = get_csv_to_df(filepath, db_name, check_header = False)\n",
    "\t\tdf = df.fillna(\"\")\n",
    "\t\t\n",
    "\t\t# 2/ load table structure\n",
    "\t\tschemepath = database_scheme[db_name]\n",
    "\t\twith open(schemepath,'r') as f:\n",
    "\t\t\tscheme = f.read()\n",
    "\n",
    "\t\tprint(\"#1 : drop previous copy table..\")\n",
    "\t\tex = execute_query(connection, f\"DROP TABLE IF EXISTS`{db_name}_copy`\")\n",
    "\t\tprint(\"#2 : copy last table in new table\")\n",
    "\t\tex = execute_query(connection, f\"CREATE TABLE `{db_name}_copy` select * from `{db_name}`\")\n",
    "\t\tprint(f\"#3 : drop {db_name}\")\n",
    "\t\tex = execute_query(connection, f\"DROP TABLE IF EXISTS `{db_name}`\")\n",
    "\t\tprint(f\"#4 : create table {db_name} \")\n",
    "\t\tex = execute_query(connection, scheme) # Create new table\n",
    "\t\t\n",
    "\t\t# 3/ Repopulate db\n",
    "\t\tex = populating_table_query(connection, df, str(db_name)) # populate table\n",
    "\t\tif ex == True :\n",
    "\t\t\tfilename = database_filename[db_name]\n",
    "\t\t\t#move_to_folder(filename, PARENT_PATH, ARCHIVE_PATH) # move file into archive folder\n",
    "\t\telse :\n",
    "\t\t\tprint(\"Something went wrong.. Table replaced with latest copy\")\n",
    "\t\t\tex = execute_query(connection, f\"DROP TABLE IF EXISTS `{db_name}`\")\n",
    "\t\t\tex = execute_query(connection, f\"CREATE TABLE `{db_name}` select * from `{db_name}_copy`\")\n",
    "\t\t\tii = input(\"Something went wrong, press 1 to continue, 0 to exit\")\n",
    "\t\t\tif ii == '0' :\n",
    "\t\t\t\tsys.exit()\n",
    "if len(dir_ls) == 0 :\n",
    "\tii = input(\"No data has been found, press 1 to continue, 0 to exit\")\n",
    "\tif ii == '0' :\n",
    "\t\tsys.exit()\n",
    "i = 0 \n",
    "for QUERY_ENGINEERING in QUERY_ENGINEERING_PATH :\n",
    "\twith open(QUERY_ENGINEERING ,'r',  encoding='utf-8') as f :\n",
    "\t\tdata = json.load(f)\n",
    "\n",
    "\t## Import notebook as JSON file \n",
    "\tdf = pd.DataFrame.from_dict(data['cells'])\n",
    "\tdf = df.drop([\"id\", \"metadata\", \"execution_count\", \"outputs\"], axis = 1) # Clean notebook\n",
    "\tdf = df.drop(df[df.cell_type== \"markdown\"].index )\n",
    "\n",
    "\t## Clean query \n",
    "\tdf = df.apply(lambda x : clean_query(x.source), axis = 1)\n",
    "\tif i == 0 :\n",
    "\t\traw_list = df.values\n",
    "\t\ti += 1\n",
    "\telse : \n",
    "\t\traw_list = np.append(raw_list, df.values)\n",
    "\t\ti += 1\n",
    "\n",
    "input(f'Number of workflow {len(QUERY_ENGINEERING_PATH)}. Press Enter to continue') \n",
    "query_list = split_multiple_query(raw_list)\n",
    "\n",
    "## Query launcher \n",
    "er = ''\n",
    "for query in tqdm(query_list) :\n",
    "\tprint(\"-\"*10)\n",
    "\tprint(query)\n",
    "\tex = execute_query(connection, query)\n",
    "\tprint(\"-\"*10)\n",
    "\tif ex != True :\n",
    "\t\tif 'Error' in ex and er == '' : \n",
    "\t\t\tresponse = input(f\"{ex}, press 1 to skip, 0 to exit \\t\")\n",
    "\t\t\tif response == '0' :\n",
    "\t\t\t\tsys.exit()\n",
    "\t\t\ter = ex\n",
    "\t\telif Error != '' and er != ex and 'Error' in ex : # In case the new error is not equal to the previous one\n",
    "\t\t\tresponse = input(f\"{ex}, press 1 to skip, 0 to exit \\t\")\n",
    "\t\t\tif response == '0' :\n",
    "\t\t\t\tsys.exit()\n",
    "\t\t\ter = ex\n",
    "\n",
    "## EXPORT DATA \n",
    "\n",
    "export_table_csv(TABLE_NAME)\n",
    "\n",
    "input(\"Press Enter to finish...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3a47e-5c0a-44f8-950b-dea88668496f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
